{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/feliciakiani/PolitikPedia/blob/main/Machine%20Learning/ETL_Spam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrETue2CZA00",
        "outputId": "8a8845b0-c327-4d4a-bb77-a667fc1a0e0d"
      },
      "outputs": [],
      "source": [
        "!pip install PySastrawi\n",
        "!pip install flask\n",
        "!pip install mysql.connector\n",
        "!pip install textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "yoFu5NGqZH11",
        "outputId": "1eca1c75-198a-4545-8664-832b733d4947"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "import re\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "import mysql.connector\n",
        "from textblob import TextBlob\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "AI5VN4WsgWF6"
      },
      "outputs": [],
      "source": [
        "def filters(text):\n",
        "  filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
        "  regex_pattern = '[' + re.escape(filters) + ']'\n",
        "\n",
        "  filtered_text = re.sub(regex_pattern, '', text)\n",
        "\n",
        "  return filtered_text\n",
        "\n",
        "\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "def stemming(text):\n",
        "    return stemmer.stem(text)\n",
        "\n",
        "def preprocessedText(text):\n",
        "  text = filters(text)\n",
        "  text = stemming(text)\n",
        "\n",
        "  return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV-trKpDtC4Y"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "nv5SqDRBbA94"
      },
      "outputs": [],
      "source": [
        "# #gk perlu\n",
        "# with open('sentences_spam.txt', 'w', encoding='utf-8') as file:\n",
        "#     for sentences_spam in X:\n",
        "#         file.write(sentences_spam + '\\n')\n",
        "\n",
        "# from google.colab import files\n",
        "\n",
        "# # Save the best model checkpoint to a file\n",
        "# files.download('sentences_spam.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "SVnWbnbyboXS",
        "outputId": "981798bc-249a-4198-e542-a678862568d4"
      },
      "outputs": [],
      "source": [
        "model = load_model(\"spamDetection.h5\")\n",
        "\n",
        "def spam_detection(user_id):\n",
        "  # Koneksi ke database Cloud SQL\n",
        "  conn = mysql.connector.connect(\n",
        "          host=os.getenv(\"DB_HOST\"),\n",
        "          user=os.getenv(\"DB_USERNAME\"),\n",
        "          password=os.getenv(\"DB_PASSWORD\"),\n",
        "          database=os.getenv(\"DB_NAME\")\n",
        "  )\n",
        "\n",
        "  # Buat kursor\n",
        "  cursor = conn.cursor()\n",
        "\n",
        "  #-------------------------------------------------spam_Classification-------------------------------------------#\n",
        "  # Hyperparameter, jangan diganti\n",
        "  max_words = 34\n",
        "\n",
        "  query_comments = f\"SELECT ID as comment_id, Komentar as komentar_text FROM komentar WHERE IDUser = {user_id} ORDER BY TglKomentar DESC LIMIT 1\"\n",
        "  cursor.execute(query_comments)\n",
        "  comments = cursor.fetchall()\n",
        "\n",
        "  if comments:\n",
        "    for row in comments:\n",
        "      comment_id, komentar_text = row  # Extracting comment_id and Komentar\n",
        "      print(f\"Comment ID: {comment_id}, Komentar: {komentar_text}\")\n",
        "\n",
        "   # Apply preprocessing\n",
        "    preprocessed_text = preprocessedText(komentar_text)\n",
        "\n",
        "    # Tokenize the text data\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True)\n",
        "    # tokenizer = Tokenizer(num_words=max_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True)\n",
        "    \n",
        "    # Read the content of 'sentences.txt' and split it into lines\n",
        "    with open('sentences_spam.txt', 'r', encoding='utf-8') as file:\n",
        "      tokenizer_sentences = file.read().splitlines()\n",
        "    tokenizer.fit_on_texts(tokenizer_sentences)\n",
        "\n",
        "    # Tokenize and pad the new text\n",
        "    new_sequence = tokenizer.texts_to_sequences([preprocessed_text])\n",
        "    new_padded_sequence = pad_sequences(new_sequence, maxlen=max_words, padding='post')\n",
        "\n",
        "    # Make predictions\n",
        "    prediction = model.predict(new_padded_sequence)\n",
        "\n",
        "    # Extract the scalar value from the NumPy array\n",
        "    confidence = prediction[0, 0]\n",
        "\n",
        "    # Threshold for considering a label as positive\n",
        "    threshold = 0.5\n",
        "\n",
        "    # Interpret prediction\n",
        "    predicted_class = 1 if confidence >= threshold else 0\n",
        "\n",
        "    # Convert confidence to a format that can be handled by format method\n",
        "    confidence_str = '{:.4f}'.format(confidence)\n",
        "\n",
        "    print(f\"User ID: {user_id}, Comment ID: {comment_id}, Predicted Class: {predicted_class} (Confidence: {confidence_str})\")\n",
        "\n",
        "    # Return the results\n",
        "    result = {\n",
        "        \"comment_id\": comment_id,\n",
        "        \"predicted_class\": predicted_class,\n",
        "        \"confidence\": confidence_str\n",
        "    }\n",
        "  else:\n",
        "    result = {\"error\": f\"Comment with ID {user_id} not found.\"}\n",
        "  \n",
        "  # Close the database connection\n",
        "  cursor.close()\n",
        "  conn.close()\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:8888\n",
            " * Running on http://192.168.1.56:8888\n",
            "Press CTRL+C to quit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comment ID: 36, Komentar: Selamat! 200 IMPoin dri isi ulang pulsa BERHASIL msk ke akunmu. Poin hangus pd 31-12-2023.\n",
            "1/1 [==============================] - 0s 120ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "192.168.1.56 - - [19/Dec/2023 22:24:38] \"GET /spam_detection/14 HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User ID: 14, Comment ID: 36, Predicted Class: 0 (Confidence: 0.3611)\n",
            "{'comment_id': 36, 'predicted_class': 0, 'confidence': '0.3611'}\n",
            "Comment ID: 37, Komentar: Selamat! 200 IMPoin dri isi ulang pulsa BERHASIL msk ke akunmu. Poin hangus pd 31-12-2023. Terus kumpulkan Poin & tukar dgn reward menarik di *999# atau bit.ly/imnm3. Jangan lewatkan kesempatan ini!\n",
            "1/1 [==============================] - 0s 53ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "192.168.1.56 - - [19/Dec/2023 22:27:16] \"GET /spam_detection/14 HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User ID: 14, Comment ID: 37, Predicted Class: 1 (Confidence: 0.5903)\n",
            "{'comment_id': 37, 'predicted_class': 1, 'confidence': '0.5903'}\n"
          ]
        }
      ],
      "source": [
        "# flask\n",
        "from flask import Flask, jsonify, request\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/spam_detection/<string:userId>', methods=['GET'])\n",
        "def spam_detection_endpoint(userId):\n",
        "\n",
        "    result = spam_detection(userId)\n",
        "    print(result)\n",
        "    return jsonify(result)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=8888)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO8STlmBXG3dGzfx+dgsZTJ",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
